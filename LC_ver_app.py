import streamlit as st
import pandas as pd
import os
from dotenv import load_dotenv

# --- LangChain ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ ---
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser, StrOutputParser
from langchain_core.runnables import RunnableLambda

# --- 0. í˜ì´ì§€ ê¸°ë³¸ ì„¤ì • ë° ìŠ¤íƒ€ì¼ ---
st.set_page_config(page_title="ìŠ¤íƒ€íŠ¸ì—… ë„¤ë¹„ê²Œì´í„°", page_icon="ğŸ§­")

# ì‚¬ìš©ì ë§í’ì„  ìŠ¤íƒ€ì¼ì„ ìœ„í•œ CSS
st.markdown("""
<style>
    .user-message-container {
        display: flex;
        justify-content: flex-end;
        margin-bottom: 10px;
    }
    .user-message {
        background-color: #DCF8C6; /* ì—°ë‘ìƒ‰ ë°°ê²½ */
        color: black;
        border-radius: 15px;
        padding: 10px 15px;
        display: inline-block;
        max-width: 80%;
        position: relative;
        margin-right: 10px;
        text-align: left;
    }
    .user-message:after {
        content: '';
        position: absolute;
        top: 10px;
        right: -10px;
        width: 0;
        height: 0;
        border-top: 10px solid transparent;
        border-bottom: 10px solid transparent;
        border-left: 10px solid #DCF8C6;
    }
</style>
""", unsafe_allow_html=True)


# --- 1. ë°ì´í„° ë° LangChain ì»´í¬ë„ŒíŠ¸ ë¡œë“œ ---
@st.cache_resource
def load_data_and_components():
    """ë¯¸ë¦¬ ìƒì„±ëœ ë°ì´í„°í”„ë ˆì„ê³¼ FAISS ë²¡í„° ì €ì¥ì†Œë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        df = pd.read_pickle('vector_store.pkl')
        embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
        vector_store = FAISS.load_local("faiss_index", embeddings, allow_dangerous_deserialization=True)
        retriever = vector_store.as_retriever(search_kwargs={"k": 5})
        return df, retriever
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}. build_vector_store.pyë¥¼ ë¨¼ì € ì‹¤í–‰í–ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return None, None

# --- .env íŒŒì¼ì—ì„œ API í‚¤ ë¡œë“œ ---
load_dotenv()
if not os.getenv('OPENAI_API_KEY'):
    st.error("OpenAI API í‚¤ë¥¼ .env íŒŒì¼ì— ì„¤ì •í•´ì£¼ì„¸ìš”.")
    st.stop()

# --- ë°ì´í„° ë° LangChain ì»´í¬ë„ŒíŠ¸ ë¡œë“œ ---
all_books_df, retriever = load_data_and_components()
if retriever is None:
    st.stop()
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

# --- ì´ë¯¸ì§€ URL ---
COVER_IMAGES = {
    'ë¦° ìŠ¤íƒ€íŠ¸ì—…': 'https://image.yes24.com/goods/7921251/XL',
    'ì œë¡œ íˆ¬ ì›': 'https://image.yes24.com/goods/103990890/XL',
    'ë¹„ì¦ˆë‹ˆìŠ¤ ì•„ì´ë””ì–´ì˜ íƒ„ìƒ': 'https://image.yes24.com/goods/91868851/XL',
    'ê¸°ì—… ì°½ì—…ê°€ ë§¤ë‰´ì–¼': 'https://image.yes24.com/goods/11928450/XL',
    'ì•„ì´ë””ì–´ ë¶ˆíŒ¨ì˜ ë²•ì¹™': 'https://image.yes24.com/goods/89707566/XL',
    'ê·¸ëƒ¥ í•˜ëŠ” ì‚¬ëŒ': 'https://image.yes24.com/goods/146284662/XL',
    'ë¸Œëœë“œ ì°½ì—… ë§ˆìŠ¤í„°': 'https://image.yes24.com/goods/148175776/XL',
    'ì°½ì—…ì´ ë§‰ë§‰í•  ë•Œ í•„ìš”í•œ ì±…': 'https://image.yes24.com/goods/147973900/XL',
    'ë§ˆì¼€íŒ… ì„¤ê³„ì': 'https://image.yes24.com/goods/116255710/XL',
    'ìŠ¤íƒ€íŠ¸ì—… ì„¤ê³„ì': 'https://image.yes24.com/goods/145757238/XL',
    'ë¸Œëœë“œ ì„¤ê³„ì': 'https://image.yes24.com/goods/120242691/XL',
    '24ì‹œê°„ ì™„ì„±! ì±—GPT ìŠ¤íƒ€íŠ¸ì—… í”„ë¡¬í”„íŠ¸ ì„¤ê³„': 'https://image.yes24.com/goods/142637189/XL',
    'íˆ¬ììëŠ” ë¬´ì—‡ì— ê½‚íˆëŠ”ê°€': 'https://image.yes24.com/goods/150108736/XL',
    'ìŠ¤í† ë¦¬ ì„¤ê³„ì': 'https://image.yes24.com/goods/130167416/XL',
    'ìŠ¤íƒ€íŠ¸ì—… 30ë¶„ íšŒê³„': 'https://image.yes24.com/goods/148063482/XL',
    'ì„¸ê· ë¬´ê¸°ì˜ ìŠ¤íƒ€íŠ¸ì—… ë°”ìš´ìŠ¤ë°±': 'https://image.yes24.com/goods/147976182/XL',
    'VC ìŠ¤íƒ€íŠ¸ì—…': 'https://image.yes24.com/goods/125313295/XL',
    'ìŠ¤íƒ€íŠ¸ì—… HR íŒ€ì¥ë“¤': 'https://image.yes24.com/goods/126338963/XL',
    'ìŠ¤íƒ€íŠ¸ì—… ìê¸ˆì¡°ë‹¬ ë°”ì´ë¸”': 'https://image.yes24.com/goods/123878435/XL',
    'ìŠ¤íƒ€íŠ¸ì—… ë””ìì¸ ì”½í‚¹': 'https://image.yes24.com/goods/116605554/XL'
}

# --- Session State ì´ˆê¸°í™” ---
if "messages" not in st.session_state:
    st.session_state.messages = []
    st.session_state.context = {"stage": None, "challenge": None}
    st.session_state.step = "stage_selection"

# ==============================================================================
# ëª¨ë“  í•¨ìˆ˜ ì •ì˜
# ==============================================================================

# --- LangChain ì²´ì¸(Chain) ì •ì˜ ---
def format_docs(docs):
    """ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ í”„ë¡¬í”„íŠ¸ì— ë„£ê¸° ì¢‹ì€ í˜•íƒœë¡œ í¬ë§·í•©ë‹ˆë‹¤."""
    return "\n\n".join(f"- **{doc.metadata['name']}** (ì €ì: {doc.metadata['author']}): {doc.metadata['intro']}" for doc in docs)

def create_augmented_query(inputs):
    """ì‚¬ìš©ì ì •ë³´ë¥¼ í¬í•¨í•˜ì—¬ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ê°•í™”í•©ë‹ˆë‹¤."""
    return f"ì„±ì¥ ë‹¨ê³„: {inputs['stage']}, ë‹¹ë©´ ê³¼ì œ: {inputs['challenge']}, êµ¬ì²´ì ì¸ ê³ ë¯¼: {inputs['user_prompt']}"

# 1. ì§ˆë¬¸ ì˜ë„ ë¶„ë¥˜ ì²´ì¸ (Router)
routing_prompt = ChatPromptTemplate.from_template(
    """ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ ì˜ë„ë¥¼ ë¶„ì„í•˜ëŠ” AIì…ë‹ˆë‹¤.
    ì‚¬ìš©ìì˜ ë§ˆì§€ë§‰ ì§ˆë¬¸ì´ 'ìƒˆë¡œìš´ ì£¼ì œì˜ ì±… ì¶”ì²œ'ì„ ìš”êµ¬í•˜ëŠ” ê²ƒì¸ì§€, ì•„ë‹ˆë©´ 'ì´ì „ì— ì¶”ì²œëœ ì±…ì— ëŒ€í•œ ì¶”ê°€ ì§ˆë¬¸'ì¸ì§€ íŒë‹¨í•˜ì„¸ìš”.

    [ëŒ€í™” ê¸°ë¡]
    {conversation_history}

    [ì‚¬ìš©ìì˜ ë§ˆì§€ë§‰ ì§ˆë¬¸]
    "{user_prompt}"

    [íŒë‹¨ ê¸°ì¤€]
    - "ë‹¤ë¥¸ ì±… ì¶”ì²œí•´ì¤˜", "ë§ˆì¼€íŒ… ê´€ë ¨ ì±… ì°¾ì•„ì¤˜", "~ì— ëŒ€í•œ ì±… ìˆì–´?" ì™€ ê°™ì´ ìƒˆë¡œìš´ ì£¼ì œê°€ ëª…ì‹œë˜ë©´ 'new_recommendation'ì…ë‹ˆë‹¤.
    - "ê·¸ ì±…ì— ëŒ€í•´ ë” ì•Œë ¤ì¤˜", "ì €ìê°€ ëˆ„êµ¬ì•¼?", "MVPê°€ ë­ì•¼?" ì™€ ê°™ì´ ì´ì „ ëŒ€í™”ì˜ ëŒ€ìƒì„ ê°€ë¦¬í‚¤ëŠ” ëŒ€ëª…ì‚¬ê°€ ìˆê±°ë‚˜, ëŒ€í™”ì˜ ë§¥ë½ì„ ì´ì–´ê°€ëŠ” ì§ˆë¬¸ì´ë©´ 'deepen_discussion'ì…ë‹ˆë‹¤.

    [ì¶œë ¥]
    'new_recommendation' ë˜ëŠ” 'deepen_discussion' ì¤‘ í•˜ë‚˜ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”.
    """
)
routing_chain = routing_prompt | llm | StrOutputParser()

# 2. ì±… ì¶”ì²œ ì²´ì¸ (RAG)
recommendation_template = """
ë‹¹ì‹ ì€ ìŠ¤íƒ€íŠ¸ì—… ì°½ì—…ê°€ë¥¼ ë•ëŠ” ì„¸ê³„ ìµœê³ ì˜ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤.
[ì‚¬ìš©ì ì •ë³´]
- ì„±ì¥ ë‹¨ê³„: '{stage}'
- ë‹¹ë©´ ê³¼ì œ: '{challenge}'
- êµ¬ì²´ì ì¸ ê³ ë¯¼: "{user_prompt}"
[1ì°¨ ë¶„ì„ ê²°ê³¼: ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ì±… í›„ë³´ ëª©ë¡]
{retrieved_books}
[ìµœì¢… ë¯¸ì…˜]
1. [ìˆœìœ„ ê²°ì •] 'í›„ë³´ ëª©ë¡' ì¤‘ì—ì„œ ì‚¬ìš©ìì˜ 'êµ¬ì²´ì ì¸ ê³ ë¯¼'ì„ í•´ê²°í•˜ëŠ” ë° ê°€ì¥ ì í•©í•œ ì±…ì„ 1, 2, 3ìˆœìœ„ë¡œ ê²°ì •í•˜ì„¸ìš”. ì±… ì œëª©ì€ í›„ë³´ ëª©ë¡ì— ìˆëŠ” ê²ƒê³¼ ì •í™•íˆ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.
2. [ê·¼ê±° ê°•í™” ë¦¬ì„œì¹˜] 1ìˆœìœ„ ì±…ì— ëŒ€í•´, ì¶”ì²œì˜ ì‹ ë¢°ë„ë¥¼ ë†’ì¼ **êµ¬ì²´ì ì¸ ê·¼ê±°**ë¥¼ ì œì‹œí•˜ì„¸ìš”. 'OOO ìŠ¤íƒ€íŠ¸ì—…' ê°™ì€ ëª¨í˜¸í•œ í‘œí˜„ì€ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”. ì‹¤ì œ ì‚¬ë¡€ë¥¼ ì°¾ê¸° ì–´ë µë‹¤ë©´, ì €ìì˜ ë‹¤ë¥¸ ì•„í‹°í´, ìœ ëª…ì¸ì˜ ê¸ì •ì ì¸ ë¦¬ë·° ë“±ì„ **ê°€ìƒì˜ ì›¹ ê²€ìƒ‰ ê²°ê³¼**ì²˜ëŸ¼ ë§Œë“¤ì–´ ê·¼ê±°ë¡œ ì œì‹œí•˜ì„¸ìš”.
3. [ëª©ì°¨ ê²€ìƒ‰] 1ìˆœìœ„ ì±…ì˜ **ì‹¤ì œ ëª©ì°¨**ë¥¼ ê°€ìƒì˜ ì›¹ ê²€ìƒ‰ì„ í†µí•´ ì°¾ì•„ì„œ, ë‚´ìš©ì— ë§ê²Œ ì¤„ë°”ê¿ˆ(\\n)ì„ í¬í•¨í•œ í…ìŠ¤íŠ¸ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”.
4. [ì ìš© ë°©í–¥ ì œì•ˆ] ê²€ìƒ‰í•œ ëª©ì°¨ë¥¼ ì°¸ê³ í•˜ì—¬, ì‚¬ìš©ìê°€ ìì‹ ì˜ ìŠ¤íƒ€íŠ¸ì—…ì— **ì–´ë–»ê²Œ ì ìš©í•´ë³¼ ìˆ˜ ìˆì„ì§€** êµ¬ì²´ì ì¸ ì˜ˆì‹œë¥¼ 2~3ê°€ì§€ ì œì•ˆí•´ì£¼ì„¸ìš”. **ë°˜ë“œì‹œ ê° ì œì•ˆì„ "1. ", "2. " ì™€ ê°™ì´ ìˆ«ìë¡œ ì‹œì‘í•˜ê³  ì¤„ë°”ê¿ˆ(\\n)ìœ¼ë¡œ êµ¬ë¶„ëœ ëª…í™•í•œ ë¦¬ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.**
5. [í›„ì† ì§ˆë¬¸ ìƒì„±] ì‚¬ìš©ìê°€ ì´ì–´ì„œ ê¶ê¸ˆí•´í•  ë§Œí•œ **í›„ì† ì§ˆë¬¸ 3ê°œ**ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
6. [ìµœì¢… ë‹µë³€ ìƒì„±] ìœ„ì˜ ëª¨ë“  ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬, ì•„ë˜ JSON í˜•ì‹ì— ë§ì¶° ìµœì¢… ë‹µë³€ì„ ìƒì„±í•˜ì„¸ìš”.
```json
{{
  "best_book": {{"title": "<1ìˆœìœ„ ì±… ì œëª©>", "author": "<1ìˆœìœ„ ì±… ì €ì>"}},
  "new_reason": "<ê·¼ê±° ê°•í™” ë¦¬ì„œì¹˜ ê²°ê³¼ë¥¼ í¬í•¨í•œ, ìƒˆë¡­ê²Œ ìƒì„±ëœ ë§ì¶¤ ì¶”ì²œ ì´ìœ >",
  "table_of_contents": "<ê²€ìƒ‰ìœ¼ë¡œ ì°¾ì€, ì¤„ë°”ê¿ˆìœ¼ë¡œ ì •ë¦¬ëœ ëª©ì°¨ í…ìŠ¤íŠ¸>",
  "application_points": "<ìˆ«ì ë¦¬ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ì‘ì„±ëœ êµ¬ì²´ì ì¸ ì ìš© ë°©í–¥ ì œì•ˆ>",
  "second_and_third_books": [
    {{"title": "<2ìˆœìœ„ ì±… ì œëª©>", "author": "<2ìˆœìœ„ ì±… ì €ì>"}},
    {{"title": "<3ìˆœìœ„ ì±… ì œëª©>", "author": "<3ìˆœìœ„ ì±… ì €ì>"}}
  ],
  "follow_up_questions": ["<ìƒì„±ëœ í›„ì† ì§ˆë¬¸ 1>", "<ìƒì„±ëœ í›„ì† ì§ˆë¬¸ 2>", "<ìƒì„±ëœ í›„ì† ì§ˆë¬¸ 3>"]
}}
```
"""
recommendation_prompt = ChatPromptTemplate.from_template(recommendation_template)
recommendation_parser = JsonOutputParser()

recommendation_chain = (
    {
        "retrieved_books": RunnableLambda(create_augmented_query) | retriever | RunnableLambda(format_docs),
        "user_prompt": lambda x: x["user_prompt"],
        "stage": lambda x: x["stage"],
        "challenge": lambda x: x["challenge"],
    }
    | recommendation_prompt
    | llm
    | recommendation_parser
)

# 3. ì‹¬í™” ì§ˆë¬¸ ë‹µë³€ ì²´ì¸
deepen_template = """
ë‹¹ì‹ ì€ ìŠ¤íƒ€íŠ¸ì—… ì „ë¬¸ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤. ì•„ë˜ëŠ” ì‚¬ìš©ìì™€ì˜ ì´ì „ ëŒ€í™” ê¸°ë¡ì…ë‹ˆë‹¤.
[ëŒ€í™” ê¸°ë¡]
{conversation_history}
[ì‚¬ìš©ìì˜ ìƒˆë¡œìš´ ì§ˆë¬¸]
"{user_prompt}"
[ë¯¸ì…˜]
ëŒ€í™”ì˜ ë§¥ë½ì„ ì™„ë²½í•˜ê²Œ íŒŒì•…í•œ í›„, ì‚¬ìš©ìì˜ 'ìƒˆë¡œìš´ ì§ˆë¬¸'ì— ëŒ€í•´ ì›¹ ê²€ìƒ‰ì„ í†µí•´ ì°¾ì€ ì •ë³´ì²˜ëŸ¼ êµ¬ì²´ì ì´ê³  ê¹Šì´ ìˆëŠ” ë‹µë³€ì„ í•´ì£¼ì„¸ìš”.
"""
deepen_prompt = ChatPromptTemplate.from_template(deepen_template)
deepen_chain = deepen_prompt | llm | StrOutputParser()

# --- ì¶”ì²œ ê²°ê³¼ í‘œì‹œ í•¨ìˆ˜ ---
def display_recommendation(reco, message_index):
    """AIì˜ ì¶”ì²œ ê²°ê³¼ë¥¼ UIì— ì˜ˆì˜ê²Œ í‘œì‹œí•©ë‹ˆë‹¤."""
    if not isinstance(reco, dict) or "best_book" not in reco:
        st.error("AIë¡œë¶€í„° ìœ íš¨í•œ ë‹µë³€ì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        st.write("ë°›ì€ ë‹µë³€:", reco)
        return

    best_book_info = reco.get('best_book', {})
    best_book_title = best_book_info.get('title')

    if not best_book_title:
        st.error("AIê°€ ì ì ˆí•œ ì±…ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì§ˆë¬¸ì„ ì¢€ ë” êµ¬ì²´ì ìœ¼ë¡œ í•´ì£¼ì‹œê² ì–´ìš”?")
        return

    filtered_df = all_books_df[all_books_df['name'] == best_book_title]
    if filtered_df.empty:
        st.error(f"AIê°€ ì¶”ì²œí•œ '{best_book_title}' ì±…ì„ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    best_book_details = filtered_df.iloc[0]

    st.success("AIê°€ ë‹¹ì‹ ì˜ ê³ ë¯¼ì„ ìœ„í•´ ê³ ë¥¸ ë§ì¶¤ ì¶”ì²œ ë„ì„œì…ë‹ˆë‹¤!")

    col1, col2 = st.columns([1, 2])
    with col1:
        st.image(COVER_IMAGES.get(best_book_title, "https://placehold.co/150x220/EEE/31343C?text=No+Cover"), use_container_width=True)
    with col2:
        st.subheader(f"ğŸ“– {best_book_title}")
        st.markdown(f"**ì €ì:** {best_book_info.get('author')}")

    st.markdown("#### ğŸ¤” AIì˜ ë§ì¶¤ ì¶”ì²œ ì´ìœ ")
    st.info(reco.get('new_reason'))

    st.markdown("#### ğŸ’¡ ì´ ì±…ì˜ ì ìš© ë°©í–¥ ì œì•ˆ")
    st.warning(reco.get('application_points'))

    with st.expander("ì¶”ì²œ ë„ì„œ ì±…ì†Œê°œ ë° ëª©ì°¨ ë³´ê¸°"):
        st.markdown("##### **ì±… ì†Œê°œ**")
        intro_text = best_book_details.get('intro', 'ì†Œê°œ ì •ë³´ ì—†ìŒ')
        st.write(intro_text)
        st.markdown("---")
        st.markdown("##### **ëª©ì°¨**")
        table_text = reco.get('table_of_contents', 'ëª©ì°¨ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.')
        st.text(table_text)

    other_books = reco.get('second_and_third_books', [])
    if other_books:
        st.markdown("---")
        st.markdown("##### ğŸ“š í•¨ê»˜ ì½ìœ¼ë©´ ì¢‹ì€ ì±…ë“¤")
        cols = st.columns(len(other_books))
        for i, book in enumerate(other_books):
            with cols[i]:
                book_title = book.get('title')
                st.image(COVER_IMAGES.get(book_title, "https://placehold.co/100x150/EEE/31343C?text=No+Cover"), use_container_width=True)
                st.write(f"**{book_title}**")
                st.caption(f"_{book.get('author')}_")

    follow_up_questions = reco.get('follow_up_questions', [])
    if follow_up_questions:
        st.markdown("---")
        st.markdown("##### ğŸ’¬ ì¶”ê°€ë¡œ ì§ˆë¬¸í•´ ë³´ì„¸ìš”")
        for i, question in enumerate(follow_up_questions):
            if st.button(question, key=f"follow_up_{message_index}_{i}", use_container_width=True):
                st.session_state.messages.append({"role": "user", "content": question})
                st.session_state.step = "generating_response"
                st.rerun()

# --- ëŒ€í™” ê¸°ë¡ ê°€ê³µ í•¨ìˆ˜ ---
def create_conversation_history_string(messages):
    """ëŒ€í™” ê¸°ë¡(messages)ì„ LLMì´ ì´í•´í•˜ê¸° ì‰¬ìš´ ìì—°ì–´ ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    history = []
    for msg in messages:
        role = msg.get("role")
        content = msg.get("content")
        if role == "user":
            history.append(f"ì‚¬ìš©ì: {content}")
        elif role == "assistant":
            if isinstance(content, dict):
                book_title = content.get('best_book', {}).get('title', 'ì•Œ ìˆ˜ ì—†ëŠ” ì±…')
                summary = f"AI: '{book_title}' ì±…ì„ í¬í•¨í•œ ê´€ë ¨ ì •ë³´ë¥¼ ì¶”ì²œí–ˆìŠµë‹ˆë‹¤."
                history.append(summary)
            else:
                history.append(f"AI: {content}")
    return "\n".join(history)


# --- ë©”ì¸ ë¡œì§ (ìˆ˜ì •ë¨) ---
def handle_chat(prompt, is_initial_question=False):
    """ì‚¬ìš©ì ì…ë ¥ì„ ë°›ì•„ ì ì ˆí•œ ì²´ì¸ì„ í˜¸ì¶œí•˜ê³  AI ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤."""
    response_content = None
    try:
        # ì²« ì§ˆë¬¸ì¼ ê²½ìš°, ë¬´ì¡°ê±´ ì¶”ì²œ ì²´ì¸ ì‹¤í–‰
        if is_initial_question:
            response_content = recommendation_chain.invoke({
                "user_prompt": prompt,
                "stage": st.session_state.context['stage'],
                "challenge": st.session_state.context['challenge']
            })
        # í›„ì† ì§ˆë¬¸ì¼ ê²½ìš°, ì˜ë„ íŒŒì•… í›„ ë¶„ê¸°
        else:
            history_for_llm = create_conversation_history_string(st.session_state.messages[:-1])
            intent = routing_chain.invoke({"conversation_history": history_for_llm, "user_prompt": prompt})

            # "ìƒˆë¡œìš´ ì¶”ì²œ" ìš”ì²­ ì‹œ, 'ë‹¹ë©´ ê³¼ì œ'ë¥¼ í˜„ì¬ í”„ë¡¬í”„íŠ¸ë¡œ ë®ì–´ì“°ê³  ì¶”ì²œ ì²´ì¸ ì‹¤í–‰
            if "new_recommendation" in intent:
                response_content = recommendation_chain.invoke({
                    "user_prompt": prompt,
                    "stage": st.session_state.context['stage'],
                    "challenge": prompt  # [ìˆ˜ì •] ìƒˆë¡œìš´ ì§ˆë¬¸ì„ ìƒˆë¡œìš´ ê³¼ì œë¡œ ì‚¬ìš©
                })
            # "ì‹¬í™” ì§ˆë¬¸" ì‹œ, ê°€ê³µëœ ëŒ€í™” ê¸°ë¡ì„ í¬í•¨í•˜ì—¬ ì‹¬í™” ë‹µë³€ ì²´ì¸ ì‹¤í–‰
            else: # deepen_discussion
                response_content = deepen_chain.invoke({
                    "conversation_history": history_for_llm,
                    "user_prompt": prompt
                })

        st.session_state.messages.append({"role": "assistant", "content": response_content})

    except Exception as e:
        st.error(f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        if st.session_state.messages and st.session_state.messages[-1]['role'] == 'assistant':
            st.session_state.messages.pop()


# ==============================================================================
# ë©”ì¸ UI ë Œë”ë§ ë° ë‹¨ê³„ë³„ ë¡œì§
# ==============================================================================

st.title("ğŸ§­ ìŠ¤íƒ€íŠ¸ì—… ë„¤ë¹„ê²Œì´í„°")
st.caption("ğŸš€ ë‹¹ì‹ ì˜ ê³ ë¯¼ì— ë”± ë§ëŠ” ì±…ì„ AIê°€ ì°¾ì•„ë“œë¦½ë‹ˆë‹¤!")

# --- ëŒ€í™” ê¸°ë¡ í‘œì‹œ ---
for i, message in enumerate(st.session_state.messages):
    if message["role"] == "user":
        if i > 0:
            st.markdown("""
            <br>
            <hr style="margin-top: 20px; margin-bottom: 20px;">
            <br>
            """, unsafe_allow_html=True)
        st.markdown(f'<div class="user-message-container"><div class="user-message">{message["content"]}</div></div>', unsafe_allow_html=True)

    elif message["role"] == "assistant":
        if isinstance(message["content"], dict):
            display_recommendation(message["content"], message_index=i)
        else:
            with st.chat_message("assistant"):
                st.markdown(message["content"])

# --- ë‹¨ê³„ë³„ UI ë° ì…ë ¥ ì²˜ë¦¬ ---
if st.session_state.step == "stage_selection":
    st.info("ì•ˆë…•í•˜ì„¸ìš”! ì–´ë–¤ ê³ ë¯¼ì„ ê°€ì§€ê³  ê³„ì‹ ê°€ìš”? ë¨¼ì € í˜„ì¬ ë¹„ì¦ˆë‹ˆìŠ¤ì˜ ì„±ì¥ ë‹¨ê³„ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
    stages = ["ì•„ì´ë””ì–´ ê²€ì¦", "MVP ê°œë°œ/ì´ˆê¸° ê³ ê° í™•ë³´", "PMF(ì‹œì¥-ì œí’ˆ ì í•©ì„±) íƒìƒ‰", "ìŠ¤ì¼€ì¼ì—…/íˆ¬ì ìœ ì¹˜"]
    for stage in stages:
        if st.button(stage, use_container_width=True):
            st.session_state.context["stage"] = stage
            st.session_state.step = "challenge_selection"
            st.rerun()

elif st.session_state.step == "challenge_selection":
    st.info(f"ë„¤, '{st.session_state.context['stage']}' ë‹¨ê³„ë¥¼ ì„ íƒí•˜ì…¨êµ°ìš”. ì´ì œ ê°€ì¥ ê³ ë¯¼ë˜ëŠ” ë‹¹ë©´ ê³¼ì œë¥¼ ì„ íƒí•´ ì£¼ì„¸ìš”.")
    challenges = ["ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸/ì „ëµ", "ì œí’ˆ/ê¸°ìˆ ", "ë§ˆì¼€íŒ…/ì˜ì—…", "íŒ€/ì¡°ì§ë¬¸í™”", "íˆ¬ì/ì¬ë¬´"]
    for challenge in challenges:
        if st.button(challenge, use_container_width=True):
            st.session_state.context["challenge"] = challenge
            st.session_state.step = "problem_input"
            st.rerun()

elif st.session_state.step == "problem_input":
    st.info(f"'{st.session_state.context['challenge']}' ê³¼ì œë¥¼ ì„ íƒí•˜ì…¨êµ°ìš”. ì´ì œ ì•„ë˜ ì±„íŒ…ì°½ì— êµ¬ì²´ì ì¸ ê³ ë¯¼ì„ ììœ ë¡­ê²Œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    if prompt := st.chat_input("ì—¬ê¸°ì— ì²« ê³ ë¯¼ì„ ì…ë ¥í•˜ì„¸ìš”..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        st.session_state.step = "generating_response"
        st.rerun()

elif st.session_state.step == "generating_response":
    with st.spinner("AIê°€ ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."):
        last_prompt = st.session_state.messages[-1]["content"]
        is_initial = sum(1 for msg in st.session_state.messages if msg['role'] == 'user') == 1
        handle_chat(last_prompt, is_initial_question=is_initial)
    st.session_state.step = "chat_mode"
    st.rerun()

elif st.session_state.step == "chat_mode":
    if prompt := st.chat_input("ì¶”ê°€ì ì¸ ì§ˆë¬¸ì„ ì…ë ¥í•˜ê±°ë‚˜, ì•„ë˜ ì¶”ì²œ ì§ˆë¬¸ì„ ëˆŒëŸ¬ë³´ì„¸ìš”."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        st.session_state.step = "generating_response"
        st.rerun()
